#Run the followong scripts in order

#HMP PROJECT

  #in directory scrapeSRApy
    python scrapeSRA.py -i ../../../data/HMP/SraRunTable.txt

  #then move this directory to some cloud folder
  #mkdir <CLOUD DIR>/categories, in my case

    mkdir ~/Dropbox/biodiversity/training/BootcampAI/05/data/HMP/categories
    mv ~/Downloads/categories/* ~/Dropbox/biodiversity/training/BootcampAI/05/data/HMP/categories/
    cd ~/Dropbox/biodiversity/training/BootcampAI/05/data/HMP/categories
    ls

  #then we use a perl script to make the feature table
  #move to the scrapeSRApl directory and run, in my case

    perl SRAFeatureTable.pl -i ../../../data/HMP/categories/ -o ../../../data/HMP/HMPFeatureTable.csv

  #then we move to the training part! We'll be using Google colab, the script can be found in the directory
  #scrapeSRAjp
  #the csv file we just created can be accessed by the following link:
  #https://www.dropbox.com/s/jgeae300bbjpzm5/HMPFeatureTable.csv?dl=1

  #the colab training notebook can be found under HMP_data_training.ipynb in the scrapeSRAjp folder
